% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/efm.R
\name{adam.control}
\alias{adam.control}
\title{Adam optimization parameters}
\usage{
adam.control(
  max_epoch = 10,
  batch_size = 64,
  step_size = 0.1,
  rho = 1,
  abs_tol = 1e-06,
  beta1 = 0.9,
  beta2 = 0.999,
  epislon = 10^-8
)
}
\arguments{
\item{max_epoch}{number of optimization epoch.}

\item{batch_size}{number of data(rows) in each mini batch}

\item{step_size}{step size or learning rate for SGD.}

\item{rho}{learning rate decay through \verb{step_size/(1 + 0.1 * t^\{\\rho\})} with t being the iteration.}

\item{abs_tol}{positive convergence tolerance \verb{\\epislon}; the iterations converge when |dev - dev_{old}|/(|dev| + 0.1) < \verb{\\epsilon}.}

\item{beta1}{controls the exponential decay rate used to scale the biased first moment estimate.}

\item{beta2}{controls the exponential decay rate used to scale the biased second raw moment estimate.}

\item{epislon}{smoothing term to avoid division by zero.}
}
\value{
list of adam optimization parameters
}
\description{
Adam optimization parameters
}
